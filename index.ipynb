{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libararies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Kaggle package is installed\n",
      "INFO:__main__:Using existing zip file\n",
      "INFO:__main__:Found CSV file: realtor-data.zip.csv\n",
      "INFO:__main__:Dataset loaded successfully: 2226382 rows, 12 columns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Preview:\n",
      "   brokered_by    status     price  bed  bath  acre_lot     street  \\\n",
      "0     103378.0  for_sale  105000.0  3.0   2.0      0.12  1962661.0   \n",
      "1      52707.0  for_sale   80000.0  4.0   2.0      0.08  1902874.0   \n",
      "2     103379.0  for_sale   67000.0  2.0   1.0      0.15  1404990.0   \n",
      "3      31239.0  for_sale  145000.0  4.0   2.0      0.10  1947675.0   \n",
      "4      34632.0  for_sale   65000.0  6.0   2.0      0.05   331151.0   \n",
      "\n",
      "         city        state  zip_code  house_size prev_sold_date  \n",
      "0    Adjuntas  Puerto Rico     601.0       920.0            NaN  \n",
      "1    Adjuntas  Puerto Rico     601.0      1527.0            NaN  \n",
      "2  Juana Diaz  Puerto Rico     795.0       748.0            NaN  \n",
      "3       Ponce  Puerto Rico     731.0      1800.0            NaN  \n",
      "4    Mayaguez  Puerto Rico     680.0         NaN            NaN  \n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2226382 entries, 0 to 2226381\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Dtype  \n",
      "---  ------          -----  \n",
      " 0   brokered_by     float64\n",
      " 1   status          object \n",
      " 2   price           float64\n",
      " 3   bed             float64\n",
      " 4   bath            float64\n",
      " 5   acre_lot        float64\n",
      " 6   street          float64\n",
      " 7   city            object \n",
      " 8   state           object \n",
      " 9   zip_code        float64\n",
      " 10  house_size      float64\n",
      " 11  prev_sold_date  object \n",
      "dtypes: float64(8), object(4)\n",
      "memory usage: 203.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def check_kaggle_installation():\n",
    "    \"\"\"Verify Kaggle package is installed and credentials exist.\"\"\"\n",
    "    try:\n",
    "        import kaggle\n",
    "        logger.info(\"Kaggle package is installed\")\n",
    "        \n",
    "        # Check if credentials file exists in the default location\n",
    "        kaggle_path = Path.home() / '.kaggle' / 'kaggle.json'\n",
    "        if not kaggle_path.exists():\n",
    "            logger.error(\"Kaggle credentials not found in ~/.kaggle/kaggle.json\")\n",
    "            raise FileNotFoundError(\"Kaggle credentials not found\")\n",
    "        \n",
    "        # Check if credentials have correct permissions\n",
    "        if oct(kaggle_path.stat().st_mode)[-3:] != '600':\n",
    "            logger.warning(\"Kaggle credentials file permissions are not set to 600\")\n",
    "            logger.info(\"Setting correct permissions...\")\n",
    "            kaggle_path.chmod(0o600)\n",
    "            \n",
    "        return True\n",
    "    except ImportError:\n",
    "        logger.error(\"Kaggle package is not installed. Please run: pip install kaggle\")\n",
    "        return False\n",
    "\n",
    "def download_and_load_dataset(dataset_name, zip_filename):\n",
    "    \"\"\"Download dataset from Kaggle and load it into a DataFrame.\"\"\"\n",
    "    zip_path = Path(zip_filename)\n",
    "    \n",
    "    # Download the dataset if necessary\n",
    "    if not zip_path.exists() or zip_path.stat().st_size == 0:\n",
    "        logger.info(\"Downloading dataset from Kaggle...\")\n",
    "        try:\n",
    "            import kaggle\n",
    "            kaggle.api.authenticate()\n",
    "            kaggle.api.dataset_download_files(dataset_name, path='.', unzip=False)\n",
    "            logger.info(\"Dataset downloaded successfully\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to download dataset: {str(e)}\")\n",
    "            raise RuntimeError(f\"Dataset download failed: {str(e)}\")\n",
    "    else:\n",
    "        logger.info(\"Using existing zip file\")\n",
    "\n",
    "    # Load the dataset\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            csv_files = [f for f in zip_ref.namelist() if f.endswith('.csv')]\n",
    "            if not csv_files:\n",
    "                logger.error(\"No CSV files found in the zip archive\")\n",
    "                raise ValueError(\"No CSV files in archive\")\n",
    "                \n",
    "            logger.info(f\"Found CSV file: {csv_files[0]}\")\n",
    "            with zip_ref.open(csv_files[0]) as csv_file:\n",
    "                df = pd.read_csv(csv_file)\n",
    "                logger.info(f\"Dataset loaded successfully: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "                return df\n",
    "                \n",
    "    except zipfile.BadZipFile:\n",
    "        logger.error(\"Corrupt zip file detected\")\n",
    "        if zip_path.exists():\n",
    "            zip_path.unlink()  # Delete corrupt zip file\n",
    "        logger.info(\"Deleted corrupt zip file. Please run the script again to re-download\")\n",
    "        raise\n",
    "\n",
    "def main():\n",
    "    # Check Kaggle installation first\n",
    "    if not check_kaggle_installation():\n",
    "        sys.exit(1)\n",
    "        \n",
    "    # Dataset details\n",
    "    DATASET_NAME = 'ahmedshahriarsakib/usa-real-estate-dataset'\n",
    "    ZIP_FILENAME = 'usa-real-estate-dataset.zip'\n",
    "    \n",
    "    try:\n",
    "        # Download and load the dataset\n",
    "        df = download_and_load_dataset(DATASET_NAME, ZIP_FILENAME)\n",
    "        \n",
    "        # Basic data exploration\n",
    "        print(\"\\nDataset Preview:\")\n",
    "        print(df.head())\n",
    "        print(\"\\nDataset Info:\")\n",
    "        print(df.info())\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_sets = df[['acre_lot', 'bed', 'bath', 'city', 'state', 'house_size', 'price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Null sums------\n",
      " acre_lot      325589\n",
      "bed           481317\n",
      "bath          511771\n",
      "city            1407\n",
      "state              8\n",
      "house_size    568484\n",
      "price           1541\n",
      "dtype: int64 \n",
      "\n",
      "\n",
      "-------Data types------\n",
      "acre_lot      float64\n",
      "bed           float64\n",
      "bath          float64\n",
      "city           object\n",
      "state          object\n",
      "house_size    float64\n",
      "price         float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "null_sum = df_training_sets.isnull().sum();\n",
    "print('-------Null sums------\\n',null_sum,'\\n\\n\\n-------Data types------');\n",
    "data_types = df_training_sets.dtypes;\n",
    "print(data_types);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running baseline models with improved data preprocessing...\n",
      "\n",
      "Improved Linear Regression Performance:\n",
      "R² Score: 0.3602\n",
      "RMSE: 0.6857\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from scipy import stats\n",
    "\n",
    "def prepare_data(df):\n",
    "    \"\"\"\n",
    "    Prepare the data with improved cleaning and feature engineering\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying the original\n",
    "    df_prep = df.copy()\n",
    "    \n",
    "    # 1. Remove outliers using z-score for numeric columns\n",
    "    numeric_cols = ['price', 'house_size', 'bed', 'bath', 'acre_lot']\n",
    "    for col in numeric_cols:\n",
    "        z_scores = stats.zscore(df_prep[col], nan_policy='omit')\n",
    "        df_prep = df_prep[np.abs(z_scores) < 3]\n",
    "    \n",
    "    # 2. Log transform price (since house prices are usually log-normally distributed)\n",
    "    df_prep['price'] = np.log1p(df_prep['price'])\n",
    "    \n",
    "    # 3. Create meaningful feature interactions\n",
    "    df_prep['price_per_sqft'] = df_prep['price'] / df_prep['house_size']\n",
    "    df_prep['rooms'] = df_prep['bed'] + df_prep['bath']\n",
    "    df_prep['avg_room_size'] = df_prep['house_size'] / df_prep['rooms']\n",
    "    \n",
    "    # 4. Handle missing values more carefully\n",
    "    # For house_size, impute based on bedrooms and bathrooms\n",
    "    size_medians = df_prep.groupby(['bed', 'bath'])['house_size'].transform('median')\n",
    "    df_prep['house_size'] = df_prep['house_size'].fillna(size_medians)\n",
    "    \n",
    "    # For remaining numeric columns, use median\n",
    "    for col in ['bed', 'bath', 'acre_lot']:\n",
    "        df_prep[col] = df_prep[col].fillna(df_prep[col].median())\n",
    "    \n",
    "    # 5. Scale numeric features using RobustScaler (less sensitive to outliers)\n",
    "    scaler = RobustScaler()\n",
    "    df_prep[numeric_cols] = scaler.fit_transform(df_prep[numeric_cols])\n",
    "    \n",
    "    # 6. Encode categorical variables\n",
    "    for col in ['city', 'state']:\n",
    "        # Calculate frequency encoding\n",
    "        freq_enc = df_prep[col].value_counts(normalize=True)\n",
    "        # Apply encoding and handle missing values\n",
    "        df_prep[f'{col}_freq'] = df_prep[col].map(freq_enc).fillna(0)\n",
    "    \n",
    "    # Drop original categorical columns after encoding\n",
    "    df_prep = df_prep.drop(['city', 'state'], axis=1)\n",
    "    \n",
    "    return df_prep\n",
    "\n",
    "# Prepare the data\n",
    "df_cleaned = prepare_data(df_training_sets)\n",
    "\n",
    "# Split the data\n",
    "X = df_cleaned.drop('price', axis=1)\n",
    "y = df_cleaned['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Run baseline models again with improved data\n",
    "print(\"Running baseline models with improved data preprocessing...\")\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Simple linear regression with all features\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "y_pred = lr_model.predict(X_test)\n",
    "\n",
    "print(\"\\nImproved Linear Regression Performance:\")\n",
    "print(f\"R² Score: {r2_score(y_test, y_pred):.4f}\")\n",
    "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training sample...\n",
      "Training Random Forest on sample...\n",
      "Evaluating model...\n",
      "\n",
      "Random Forest Performance:\n",
      "R² Score: 0.6422\n",
      "RMSE: 0.5127\n",
      "\n",
      "Top 5 Most Important Features:\n",
      "          feature  importance\n",
      "2            bath    0.425979\n",
      "8      state_freq    0.239833\n",
      "3      house_size    0.150503\n",
      "4  price_per_sqft    0.139558\n",
      "6   avg_room_size    0.021998\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# 1. Sample the data for faster processing\n",
    "def create_sample(X, y, sample_size=100000, random_state=42):\n",
    "    \"\"\"Create a random sample of the data\"\"\"\n",
    "    if len(X) > sample_size:\n",
    "        X_sample, _, y_sample, _ = train_test_split(\n",
    "            X, y, \n",
    "            train_size=sample_size, \n",
    "            random_state=random_state\n",
    "        )\n",
    "        return X_sample, y_sample\n",
    "    return X, y\n",
    "\n",
    "# 2. Create training sample\n",
    "print(\"Creating training sample...\")\n",
    "X_sample, y_sample = create_sample(X_train, y_train, sample_size=100000)\n",
    "\n",
    "# 3. Train Random Forest on sample\n",
    "print(\"Training Random Forest on sample...\")\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=50,  # Reduced number of trees\n",
    "    max_depth=8,      # Limited depth\n",
    "    min_samples_split=10,\n",
    "    n_jobs=-1,        # Use all CPU cores\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_model.fit(X_sample, y_sample)\n",
    "\n",
    "# 4. Evaluate on test set\n",
    "print(\"Evaluating model...\")\n",
    "y_pred = rf_model.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(\"\\nRandom Forest Performance:\")\n",
    "print(f\"R² Score: {r2:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "\n",
    "# 5. Feature importance analysis\n",
    "importances = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 5 Most Important Features:\")\n",
    "print(importances.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Housing Price Pred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
